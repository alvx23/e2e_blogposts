{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16e2ce0",
   "metadata": {},
   "source": [
    "# Part 2: Data Preparation\n",
    " ----\n",
    "\n",
    "Note this Demo is based on ngc docker image `nvcr.io/nvidia/pytorch:21.11-py3`\n",
    "\n",
    "This notebook walks you each step to train a model using containers from the NGC Catalog. We chose the GPU optimized Pytorch container as an example. The basics of working with docker containers apply to all NGC containers.\n",
    "\n",
    "We will show you how to:\n",
    "\n",
    "* Download the Xview Dataset\n",
    "* How to convert labels to coco format\n",
    "* How to conduct the preprocessing step ,Tiling: slicing large satellite imagery into chunks \n",
    "* How to upload to s3 bucket to support distributed training\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 2. Pre-reqs, set up jupyter notebook environment using NGC container \n",
    "\n",
    "# Execute docker run to create NGC environment for Data Prep\n",
    "make sure to map host directory to docker directory, we will use the host directory again to \n",
    "* `docker run   --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 -v /home/ubuntu:/home/ubuntu  -p 8008:8888 -it nvcr.io/nvidia/pytorch:21.11-py3  /bin/bash`\n",
    "\n",
    "# Run jupyter notebook command within docker container to access it on your local browser\n",
    "* `cd /home/ubuntu`\n",
    "* `jupyter lab --ip=0.0.0.0 --port=8888 --NotebookApp.token='' --NotebookApp.password=''` \n",
    "* `git clone https://github.com/interactivetech/e2e_blogposts.git`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2340c0",
   "metadata": {},
   "source": [
    "# 0. Download the Xview Dataset\n",
    "The dataset we will be using is from the DIUx xView 2018 Challenge https://challenge.xviewdataset.org by U.S. National Geospatial-Intelligence Agency (NGA). You will need to create an account at https://challenge.xviewdataset.org/welcome, agree to the terms and conditions, and download the dataset manually.\n",
    "\n",
    "You can download the dataset at the url https://challenge.xviewdataset.org/data-download\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72121b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sahi in /opt/conda/lib/python3.8/site-packages (0.11.13)\n",
      "Requirement already satisfied: scikit-image in /opt/conda/lib/python3.8/site-packages (0.20.0)\n",
      "Collecting opencv-python-headless==4.5.5.64\n",
      "  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 47.8 MB 29.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /opt/conda/lib/python3.8/site-packages (from opencv-python-headless==4.5.5.64) (1.21.4)\n",
      "Requirement already satisfied: pybboxes==0.1.6 in /opt/conda/lib/python3.8/site-packages (from sahi) (0.1.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from sahi) (2.26.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from sahi) (6.0)\n",
      "Requirement already satisfied: terminaltables in /opt/conda/lib/python3.8/site-packages (from sahi) (3.1.10)\n",
      "Requirement already satisfied: pillow>=8.2.0 in /opt/conda/lib/python3.8/site-packages (from sahi) (9.5.0)\n",
      "Requirement already satisfied: click==8.0.4 in /opt/conda/lib/python3.8/site-packages (from sahi) (8.0.4)\n",
      "Requirement already satisfied: opencv-python>=4.2.0.32 in /opt/conda/lib/python3.8/site-packages (from sahi) (4.7.0.72)\n",
      "Requirement already satisfied: fire in /opt/conda/lib/python3.8/site-packages (from sahi) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in /opt/conda/lib/python3.8/site-packages (from sahi) (4.62.3)\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.8/site-packages (from sahi) (2.0.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (0.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (2023.3.21)\n",
      "Requirement already satisfied: scipy<1.9.2,>=1.8 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (1.9.1)\n",
      "Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (21.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /opt/conda/lib/python3.8/site-packages (from scikit-image) (2.27.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->scikit-image) (3.0.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from fire->sahi) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.8/site-packages (from fire->sahi) (2.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->sahi) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->sahi) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->sahi) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests->sahi) (2.0.0)\n",
      "Installing collected packages: opencv-python-headless\n",
      "Successfully installed opencv-python-headless-4.5.5.64\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# run pip install to get the SAHI library\n",
    "!pip install sahi scikit-image opencv-python-headless==4.5.5.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c82e43cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-07 21:32:40--  https://d307kc0mrhucc3.cloudfront.net/train_images.tgz?Expires=1680923794&Signature=pn0R9k3BpSukGEdjcNx7Kvs363HWkngK8sQLHxkDOqqkDAHSOCDBmAMAsBhYZ820uMpyu4Ynp1UAV60OmUURyvGorfIRaVF~jJO8-oqRVLeO1f24OGCQg7HratHNUsaf6owCb8XXy~3zaW15FcuORuPV-2Hr6Jxekwcdw9D~g4M2dLufA~qBfTLh3uNjWK5UCAMvyPz2SRLtvc3JLzGYq1eXiKh1dI9W0DyWXov3mVDpBdwS84Q21S2lVi24KJsiZOSJqozuvahydW2AuR~tbXTRbYtmAyPF9ZqT8ZCd9MLeKw2qQJjb7tvzaSZ0F9zPjm2RS8961bo6QoBVeo6kzA__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ\n",
      "Resolving d307kc0mrhucc3.cloudfront.net (d307kc0mrhucc3.cloudfront.net)... 108.138.82.85, 108.138.82.37, 108.138.82.133, ...\n",
      "Connecting to d307kc0mrhucc3.cloudfront.net (d307kc0mrhucc3.cloudfront.net)|108.138.82.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 15413902447 (14G) [application/gzip]\n",
      "Saving to: ‘train_images.tgz’\n",
      "\n",
      "train_images.tgz    100%[===================>]  14.35G  67.0MB/s    in 3m 18s  \n",
      "\n",
      "2023-04-07 21:35:58 (74.1 MB/s) - ‘train_images.tgz’ saved [15413902447/15413902447]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example command to download train images with wget command, you will need to update the url as the token is expired\"\n",
    "!wget -O train_images.tgz \"https://d307kc0mrhucc3.cloudfront.net/train_images.tgz?Expires=1680923794&Signature=pn0R9k3BpSukGEdjcNx7Kvs363HWkngK8sQLHxkDOqqkDAHSOCDBmAMAsBhYZ820uMpyu4Ynp1UAV60OmUURyvGorfIRaVF~jJO8-oqRVLeO1f24OGCQg7HratHNUsaf6owCb8XXy~3zaW15FcuORuPV-2Hr6Jxekwcdw9D~g4M2dLufA~qBfTLh3uNjWK5UCAMvyPz2SRLtvc3JLzGYq1eXiKh1dI9W0DyWXov3mVDpBdwS84Q21S2lVi24KJsiZOSJqozuvahydW2AuR~tbXTRbYtmAyPF9ZqT8ZCd9MLeKw2qQJjb7tvzaSZ0F9zPjm2RS8961bo6QoBVeo6kzA__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b23805f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-07 21:36:02--  https://d307kc0mrhucc3.cloudfront.net/train_labels.tgz?Expires=1680923794&Signature=YEX~4gioZ7J0pAjEPx7BjJfnOa2j412mx2HlStlqa0cHj-T0T21vo17S8Fs71DXgPlZ5qnIre2-icc7wQ~EuQV-HL1ViS8qH1Aubgj9i0pnHZL07ktiyulX7QStOLywxJ7bOOmQ37iFF~-OcJW3MZfQCTWrP~LdlZMmXz0yGs5WEIYeMyvfUfIhGvrpHcJ14Z3czasSMeOKfwdQsUJoRcFTbmlbZk98IVeEWjmnGTfxGbPBdMmQ96XdT4NohggtzGdqeZhGNfwm7dKGSUbXvGCoFe~fIjBz0~5BvB6rNIaMaFuBA6aGTbCLeG8FlvijcECouhZdMTHmQUlgtSlZjGw__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ\n",
      "Resolving d307kc0mrhucc3.cloudfront.net (d307kc0mrhucc3.cloudfront.net)... 108.138.82.37, 108.138.82.133, 108.138.82.85, ...\n",
      "Connecting to d307kc0mrhucc3.cloudfront.net (d307kc0mrhucc3.cloudfront.net)|108.138.82.37|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 48950328 (47M) [application/gzip]\n",
      "Saving to: ‘train_labels.tgz’\n",
      "\n",
      "train_labels.tgz    100%[===================>]  46.68M   114MB/s    in 0.4s    \n",
      "\n",
      "2023-04-07 21:36:02 (114 MB/s) - ‘train_labels.tgz’ saved [48950328/48950328]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example command to download train images with wget command, you will need to update the url as the token is expired\"\n",
    "!wget -O train_labels.tgz \"https://d307kc0mrhucc3.cloudfront.net/train_labels.tgz?Expires=1680923794&Signature=YEX~4gioZ7J0pAjEPx7BjJfnOa2j412mx2HlStlqa0cHj-T0T21vo17S8Fs71DXgPlZ5qnIre2-icc7wQ~EuQV-HL1ViS8qH1Aubgj9i0pnHZL07ktiyulX7QStOLywxJ7bOOmQ37iFF~-OcJW3MZfQCTWrP~LdlZMmXz0yGs5WEIYeMyvfUfIhGvrpHcJ14Z3czasSMeOKfwdQsUJoRcFTbmlbZk98IVeEWjmnGTfxGbPBdMmQ96XdT4NohggtzGdqeZhGNfwm7dKGSUbXvGCoFe~fIjBz0~5BvB6rNIaMaFuBA6aGTbCLeG8FlvijcECouhZdMTHmQUlgtSlZjGw__&Key-Pair-Id=APKAIKGDJB5C3XUL2DXQ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe27705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip images and labels from /home/ubuntu/e2e_blogposts/ngc_blog\n",
    "!tar -xf train_images.tgz -C xview_dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954b3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip labels from /home/ubuntu/e2e_blogposts/ngc_blog directory \n",
    "!tar -xf train_labels.tgz -C xview_dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586201f4",
   "metadata": {},
   "source": [
    "# 1. Convert TIF to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b876ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created xview_dataset/train_images_rgb/ ...\n",
      "renaming bad named files...\n",
      "[PosixPath('xview_dataset/train_images/._100.tif'), PosixPath('xview_dataset/train_images/._109.tif'), PosixPath('xview_dataset/train_images/._102.tif')]\n",
      "[PosixPath('100.tif'), PosixPath('109.tif'), PosixPath('102.tif')]\n",
      "100%|███████████████████████████████████████| 846/846 [1:08:44<00:00,  4.88s/it]\n"
     ]
    }
   ],
   "source": [
    "# Here loop through all the images and convert them to RGB, this is important for tiling the images and training with pytorch\n",
    "# will take about an hour to complete\n",
    "!python data_utils/tif_2_rgb.py --input_dir xview_dataset/train_images \\\n",
    "  --out_dir xview_dataset/train_images_rgb/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef7628",
   "metadata": {},
   "source": [
    "# 2. How to convert labels to coco format\n",
    "Here we run a script to convert the dataset labels from .geojson format to COCO format. More details on the COCO format here: \n",
    "\n",
    "The result will be two files (in COCO formal) generated `train.json` and `val.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9fdd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(category_id_remapping='data_utils/category_id_mapping.json', output_dir='xview_dataset/', train_geojson_path='xview_dataset/xView_train.geojson', train_images_dir='xview_dataset/train_images/', train_images_dir_rgb='xview_dataset/train_images_rgb/', train_split_rate=0.75, xview_class_labels='data_utils/xview_class_labels.txt')\n",
      "5.tif:  True\n",
      "Parsing xView data: 100%|████████████| 601937/601937 [00:08<00:00, 71630.88it/s]\n",
      "Converting xView data into COCO format: 100%|█| 846/846 [00:44<00:00, 18.91it/s]\n"
     ]
    }
   ],
   "source": [
    "# make sure train_images_dir is pointing to the .tif images\n",
    "!python data_utils/convert_geojson_to_coco.py --train_images_dir xview_dataset/train_images/ \\\n",
    "  --train_images_dir_rgb xview_dataset/train_images_rgb/ \\\n",
    "  --train_geojson_path xview_dataset/xView_train.geojson \\\n",
    "  --output_dir xview_dataset/ \\\n",
    "  --train_split_rate 0.75 \\\n",
    "  --category_id_remapping data_utils/category_id_mapping.json \\\n",
    "  --xview_class_labels data_utils/xview_class_labels.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6ba6ec",
   "metadata": {},
   "source": [
    "# 3. Slicing/Tiling the Dataset\n",
    "Here we are using the SAHI library to slice our large satellite images. Satellite images can be up to 50k^2 pixels in size, which wouldnt fit in GPU memory. We alleviate this problem by slicing the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0739f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slicing step is starting...\n",
      "indexing coco dataset annotations...\n",
      "Loading coco annotations:  77%|███████████▌   | 490/634 [00:25<00:07, 18.35it/s]"
     ]
    }
   ],
   "source": [
    "!python data_utils/slice_coco.py --image_dir xview_dataset/train_images_rgb/ \\\n",
    "  --dataset_json_path xview_dataset/train.json \\\n",
    "  --slice_size 300 \\\n",
    "  --overlap_ratio 0.2 \\\n",
    "  --ignore_negative_samples True \\\n",
    "  --min_area_ratio 0.1 \\\n",
    "  --output_dir xview_dataset/train_images_rgb_no_neg/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3e2fdd",
   "metadata": {},
   "source": [
    "# 4. How to upload to s3 bucket to support distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18fb24a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389d29b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
