{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02b15f61-d287-42fd-b6fd-5be4f395a645",
   "metadata": {},
   "source": [
    "# Part 2: End-to-End Example training object detection model using NVIDIA Pytorch Container from NGC\n",
    "## Data Preparation\n",
    " ----\n",
    "\n",
    "Note this Demo is based on https://github.com/pytorch/vision/tree/v0.11.3\n",
    "\n",
    "This notebook walks you each step to train a model using containers from the NGC Catalog. We chose the GPU optimized Pytorch container as an example. The basics of working with docker containers apply to all NGC containers.\n",
    "\n",
    "We will show you how to:\n",
    "\n",
    "* Download the Xview Dataset\n",
    "* How to convert labels to coco format\n",
    "* How to conduct the preprocessing step ,Tiling: slicing large satellite imagery into chunks \n",
    "* How to upload to s3 bucket to support distributed training\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### 2. Download the TensorFlow container from the NGC Catalog \n",
    "\n",
    "Once the Docker Engine is installed on your machine, visit https://ngc.nvidia.com/catalog/containers and search for the TensorFlow container. Click on the TensorFlow card and copy the pull command.\n",
    "UPDATE IMG\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7579a1-a65f-4811-a75e-0ddf0464762c",
   "metadata": {},
   "source": [
    "# 1. Download the Xview Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece66b8d-2d96-4d00-8fba-468121245e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27421724-87f5-4dfe-8b3b-72fe927e285c",
   "metadata": {},
   "source": [
    "# 2. How to convert labels to coco format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d36a5-a465-4864-acc4-137ec74755af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56f4367d-f7da-45e3-a501-1b922f7f10f8",
   "metadata": {},
   "source": [
    "# 3. Preprocess the Dataset: Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bed6a0-bdad-4874-8236-0171d1e0d340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4503d230-cb19-4d00-b266-6ae9246b1fee",
   "metadata": {},
   "source": [
    "# 4. How to upload to s3 bucket to support distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5787fde8-ce8b-4a35-b5cc-4cea5f80948a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
